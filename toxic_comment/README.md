# Оценка токсичности комментария

### Описание проекта  
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

**Надо:** Обучить модель классифицировать комментарии на позитивные и негативные.

Имеется набор данных с разметкой о токсичности правок. Значение метрики качества F1 должно быть не меньше 0.75.

### Было сделано
Был очищен текст от ненужных символов, проведена токенизация, лемматизация. Проведена векторизация с помощью TD_IDF. Обучены модели логистической регрессии и LGBMClassifier.

### Выводы
Нашей задачей было обучить модель, чтобы она опрделяла токсичные комментарии для отправления их на модернизацию.  
Мы очистили текст от лишних символов, разбили его на отдельные слова, привели слова в начальную форму. Для оценки тональности текста мы использовали метод векторизации `TF_IDF`.  
Результаты моделей:

* `LGBMClassifier: F1 = 0.69`
* Логистическая регрессия: `F1 = 0.75`

Лучшее качество показала модель логистической регрессии.  
Проверили качество на тестовой выборке и получили значение `F1 = 0.75`, значение `ROC_AUC = 0.97`.  

Для определения тональности текста рекомендуется логистическая регрессиия.
